\section{Performance and scalability}

performance - 2 points of view - user and system
- user - response time
- system - multiple users use the app - how it impacts the performance

scaling - coping with increased load - num of requests processed, read/write ratio to the database
- vertical and horizontal scaling - autoscaling based on demand
- servers stateless - easier to scale horizontally, statefull harder

% \paragraph{performance}

% \label{chapter:serverless-startup-latency-and-platform-improvements}
% - cold starts are also one of the factors frequently raised, when discussing the performance of the serverless architecture - due to the fact that functions are running within limitted time and each event is processed independently, the cloud platform requires some time to allocate the resources and prepare the environment and initialise the function code - source of additional latency, impacting the performance from the client point of view
% - it is a topic of improvements from the providers perspective and there are services to mitigate the such as AWS Provisioned Concurrency or some programatic solutions such as plugins periodically pinging the function to stay warm

% \label{chapter:serverless-suitability-processing-time}
% - cold starts, can be especially visible when multiple functions are chained to perform some workflow - the additional latency related to cold start compounds - the unpredictability of allocating resources makes the serverless less suitable for high-performant and mission critical tasks

% \label{chapter:serverless-challenges-related-to-the-nature-of-serverless-architecture}
% - the stateless form of serverless fucntion, althoguh helps with scalability, but creates other area of problems - the fact the cfunctions needs to use external components to preserve the state as well as the lack of addressability, that implies the usage of external components to communicate - introduce additional latency, impacting the performance of such solution

% \label{chapter:comparison-with-traditional-architectures}
% - serverless suffers cold starts and that's the worst case
% - microservices, VMs can notice the performance degradation when the load increase or when it needs to be rebalanced once the cluster of container scales
% - despite the initial cold start, the serverless solution characterised with more stable performance under the increasing load

% \paragraph{scalability}

% \label{section:serverless-definition}
% - from definitions - self-autoscales and auto-proviions, based on load

% \label{chapter:serverless-autoscaling-with-proportional-cost}
% - with greater granularity of components and its stateless nature, the serverless components can easily scale horizontally, parallelising heavy workloads to meet the demand - it is automatically handled by the cloud provider to scale the services to meet the demand

% \label{chapter:serverless-development-opportunities}
% - serverless horizontal scaling as development opportunity - easier for architects to design the solution for scalability based on the underlying serverless platform

% \label{chapter:serverless-suitability-utilisation-patterns}
% - autoscaling with tracking the load with greater fidelity - makes the serverless applicable for dynamic and irregular workloads

% \label{chapter:comparison-with-traditional-architectures}
% - greater agility in terms of scaling than microservice architecture - tracking the load and responding to it with greater fidelity

---

\section{Reliability}

reliability - system works even when some failure occur, resiliency, fault tolerance
- redundancy - hardware fault, testing, monitoring, observability - software bugs

\label{section:serverless-definition}
- serverless components built with high-availability and fault-tolerance in mind - providers machines can fail, similar to regular machines - cloud platform will retry the processing accordingly, but developers need to handle the retry, error, failures

\label{chapter:serverless-development-opportunities}
- implicit failover - no longer need to run additional instance in case of failures - serverless platform will detect tha and automatically provide another computing resource to pick up the processing

\label{chapter:serverless-vendor-dependence}
- giving up the control over the system to the cloud provider, that can also have some issues and even downtimes

\label{chapter:serverless-suitability-vendor-dependence}
- cloud provider is responsible for maintaining and protectig protecting the underlying architecture, ensure sufficient level of services - however incidents happen due to unpredictable events or human errors - causing outages and connection disruption

\label{chapter:serverless-suitability-operation-types}
- implicit failover - when the function fails due some error, it can be retried up up to several times, based on configuration. It results with at least once delivery semantics

---

\section{Security and compliance}

- security - web apps process more critical workloads (banking)
- compliance - with security standards, compliance with the law for storing user data

\label{chapter:serverless-multitenancy-problem}
- multitenancy - running on the same machines as workloads of other customers of the cloud providers - preserving security and complicance in such environment - cloud providers leverage the virtualisation of resources to provide proper level of isolation between tenants' workloads

\label{chapter:serverless-security-concerns}
- serverless - opens a lot of security related questoins, the areas is not fully researched yet
- shared responsibility model - in which the cloud providers takes care of security of resources and environment the processing is executed in (monitoring services, patching vulnerabilities), but the developers needs to secure the application
- direct access to the services from the client - needs to be properly secured on the application level, to prevent from over-priviledged capabilities, doing more actions than required
- it is hard to maintain and validate the granular access policies for the functions, required to use or communicate with other components

---

\section{Maintainability}

- maintenance of application - larger cost
- operational perspective - monitoring, patching, deployemnt, maintenance - easy and automated
- development - easy, no tight modules, dependencies, inconsistency in approaches and patterns

---

% \label{section:serverless-definition}
% - from definitions - does not requires server management - does not require to maintain, provision, monitor servers and applications - overhead handed off to the provider, platform is responsible for provisioning and execution applications

% \label{chapter:serverless-reduced-development-and-operational-cost}
% - serverless is another step in infrastructure outsourcing - reducing the need to manage and maintain the hardware, the responsibility of managing servers, databases and applications transferredto the cloud provider
% - reducing the labour - no managing servers, maintaining hardware, restoring it in case of failures
- development cost and overhead can be smaller due to using the BaaS components

% \label{chapter:serverless-easier-operational-management}
% - less labour needed, no need to hire qualified admins to manage the app - to make sure the operations like scaling and ensuring that everything works fine
% - there is no need to handle deployment on the machines - most frequently using appropriate software responsible for packing the code and configuration and deploying the serverless solution, running the code and other services is handled further by the cloud provider

% \label{chapter:serverless-development-opportunities}
% - using the BaaS components, replacing existing infrastructure that includes servers, databases, pub//sub components, but also provider more advanced components capable of processing images, operating on text and voice or other AI-related features - in a matter of integration with application and billed per usage
% - it is easier to introduce changes in the architecture of application, when it is not constrained by the uderlying infrastructure - encourage to experiments, testing new features, evolving the application infrastructure

% \label{chapter:serverless-development-and-debugging}
% - new approach for building applications - lack of knowledge how to model problem can reduce the quality of services
% - new patterns are created - demand for architects aware of best practices, that can provide reference architectures
% - developing - vendors provide tooling to execute or event debug some of the components locally, but in the end the solution needs to be deployed to the cloud environemt
% - gathering logs, monitoring, distributed monitoring to trace the path of the request
% - the tooling ecosystem evolved over the years - software helping with development, operational aspects  - supporting higher level deployment techniques, allowing A/B testing, traffic shifting

% \label{chapter:serverless-testing}
% - testing - the best confidence if the service is running properly - deploying to the cloud and conduct some end-to-end tests, automation tests running in the deployment pipeline to ensure it's working properly
% - going step further - monitoring-driven development

% \label{chapter:serverless-monitoring-and-observability}
% - monitoring per component, it can be harder anyway due to stateless nature of serverless
% - distributed monitoring - especially beneficial to trace the flow of request
% - tools provided by cloud vendor, 3rd party
% - despite the fact that managing infra transfered to the cloud vendor - still plenty to do with setting up the monitoring properly, configuring alarms when some emtrics are over the limits
% - configuring deployment pipelines with checks, tests to give confidence that everything is correctly done

% \label{chapter:serverless-suitability-cloudguru}
% - serverless makes the evolvability of the architecture easier as described in example of CloudGuru, that migrated towards serverless microservice approach, while at the same time running the old services, replacing the services one by one
% - using the "inifinite" pool of resources along with par-per-use billing model - makes serveless sufficient for such experiments

---

Summary

\label{chapter:serverless-suitability}
- serverless is appealing technology tu built apps due to its benefits, but it's not free from downsides - most often some of them can be overcome, to utilise the benefits and result with 

\label{chapter:serverless-suitability-utilisation-patterns}
- serverless autoscaling capabilities - suitable for dynamic and irregular workalods - the architecture selection requires thorough cost estimation, including all the services used in the processing - ref to Euclid example

\label{chapter:serverless-suitability-processing-time}
- cold starts affects the processing time - but when the service is used from time to time, the impact should be lower - usage of dedicated services to mitigate it with some additional cost

\label{chapter:serverless-processing-limitations-tunrime-and-data-restrictions}
- even though the FaaS model seems to be pretty restricted in terms of the processing - various techniques can be applied to run event some more custom tasks - ref to Euclid example
- however, the solution built using the serverless architecture needs to be redesigned sometimes to match the platform capabilities and provide satisfactory performance

\label{chapter:serverless-suitability-operation-types}
- redesigning the processing to suit the serverless aproach and utilise resources efficiently
- event-driven approach - BaaS components creating events upon data change

\label{chapter:serverless-suitability-vendor-dependence}
- vendor dependence -giving up control to the cloud provider as a tradeoff for benefits - developing solution to have vendor lock-in in mind
- tradeoff - whether the benefits one can obtain are sufficient to sacrifice the elasticity

\label{chapter:serverless-suitability-for-web-based-workloads}
- some of the presented applications noticed cost optimisation benefits - especially with event-based workloads or highly dynamic workloads
- greater agility of development - delivering new features quicker, working on smaller units of the system - more frequent deployments

\label{chapter:serverless-suitability}
- serverless is not a silver bullet - it has appealing benefits and numerous companies adopt it successfully
- benefits - reducing operational and development cost, shortening time to market, outsourcing operational and management overhead
- fairly new approach - with some patterns and best practices already defined, but the field is in constant development and under constant improvements from the provider point of view
- also downsides and limitations

\label{chapter:serverless-suitability-utilisation-patterns}
- autoscaling with proportional billing - the cost savings most noticeable for dynamic and irregular traffic, for little traffic - leveraging the autoscaling capabilities, while for the steady workloads - VMs could be more cost effective
- one need to thoroughly estimate the cost based on the estimated traffic pattern - not easy - different pricing models and different services used in the serverless solution
- serverless reduces operational overhead - considering tradeoffs in terms of overhead vs cost

\label{chapter:serverless-suitability-processing-time}
- despite the cold starts mitigated by Provisioned Concurrency or programatic solutions - however, after that the performance is more stable, compared to the containers autoscaling

\label{chapter:serverless-processing-limitations-runtime-and-data-restrictions}
- serverless runtime is restricted - some times of processing may be not suitable (because long running processes required, fine grained coordination of processing, communication) or not unprofitable (fine grained communication) - workarounds Lambda Layer, custom container image

\label{chapter:serverless-suitability-operation-types}
- I/O bound and network bound operations needs to be redesigned, using the event-driven approach to prevent from function idle waiting - requires a mindshift

\label{chapter:serverless-suitability-vendor-dependence}
- vendor dependence is hard to mitigate, should be considered, seens as trade off, if the benefits overweigh the elasticity

\label{chapter:serverless-suitability-for-web-based-workloads}
- examples describes the cost savings when migrating event-driven workloads and when handling spiky traffic, experimenting with the architecutre/infrastructure to provide greater flexibilty

\label{chapter:comparison-with-traditional-architectures}
- serverless is more agile in terms of scalability and tracks load with greater fidelity, with contrast to containers scaling after some criteria is met, with delays and problems when rebalancing - resulting with increase in response time
- performance of serverless comparable to the VMs and containers - no performance degradation
- VMs seems cheaper, but cost is hard to predict when it comes to calculating all of the additional services - needs to be throrughly calculated / estimated based on the traffic pattern of the services
- tests performed on the heavier load of the service - what if the traffic is occasional, spiky? -> more suitable for serverless
- there is no clear choice in term of the performance, but the serverless is not that bad and event sometimes can do better than the traditional architectures, however cold start hurts

\label{chapter:serverless-suitability-performance-and-scalability}
- instant horizontal scalability of workloads
- with designing the application in a good way - the cold start and performance downsides can be at least partially mitigated
- dedicated services as Provisioned Concurrency to mitigate the cold starts
- performance from the perspective of the system - serverless has comparable performance, more stable characteristics when scaling, lower degradation ratio, when app notices increase in traffic
- fine grained scaling, handled automatically by the cloud provider in response to events

\label{chapter:serverless-suitability-reliability}
- infrastructure outsourcing, based on their knowledge and additional hardware to run the processing - more frequently they're doing great job
- preventing downtimes by deploying the applicatio nacross multiple availability zones
- implicit high availability - retrying the processing - needs to be configured to store the poisonous messages in the DLQ
- similarly to microservices - provising monitoring and observability - leveraging automation to deploy the software, urn the tests agains the test environment, additional features if it ocmes to releases - A/B testing, traffic switching, instant rollabck, feature toggling

\label{chapter:serverless-suitability-security-and-compliance}
- guidelines from cloud providers - ensuring proper configuration of the components
- components can integrate with other or be configured to ensure proper level of security
- problems due to misconfiguration

\label{chapter:serverless-suitability-maintainability}
- serverless is relatively new approach of building software, but pretty similar to the microservice architecture
- reducing operational cost and operation work
- automation for deployment, running tests, monitoring, observability
- developing and testing is harder - new approach - needs to be deployed to the cloud - some tools heping with local debugging