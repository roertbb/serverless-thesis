\chapter{Serverless computing} \label{chapter:serverless-computing}

\section{Origins} \label{section:serverless-origins}

The growth of cloud computing significantly influenced the way how server management and server application development are perceived. Around fifteen years ago, most of~the companies were entirely responsible for managing their software, altogether with the~hardware and infrastructure it was running on \cite{RobertsChapin2017}. Around that time, first services capable of outsourcing some part of infrastructure overhead emerged, which started the~idea of~cloud computing.

Amazon Web Services was one of the first service providers that enabled companies to rent computing capacity by announcing the launch of Elastic Compute Cloud (EC2) in~August 2006. It was the first Infrastructure as a Service (IaaS) product on the market that allowed companies to run their server applications on Amazon's machines that are~billed per usage time and are available within minutes from requesting new resources.

Leveraging such a service model brings a handful of benefits. It reduces the labour cost by outsourcing hardware management to the provider and infrastructure cost by paying based on actual usage of services. Furthermore, it enables companies to scale the number and type of servers in correlation with the traffic and demand for processing. Finally, it~encourages testing new solutions developed by companies and decrease the lead time, by~making the required infrastructure available within minutes instead of months, utilising favourable billing flexibility.

The cost of IaaS solutions is profitable to providers, because of technical improvements done in terms of hardware virtualization and the economy of scale on which they operate. Shortly after, other vendors such as Microsoft, Google and DigitalOcean embraced the notion of public cloud by providing services and resources from their own data centers. At~the~same time, tools like Open Stack enabled companies to use hardware from their own data centers in the same way, forming the idea of private cloud.

The next step in the cloud evolution is Platform as a Service (PaaS). As~a~layer on~top of IaaS, it adds operating system to the outsourced infrastructure stack, enabling to~deploy the application code directly. In that model, the platform takes responsibility for~managing the operating system as well as monitoring and running the application. Google App Engine, AWS Elastic Beanstalk and Heroku platform can be distinguished as most popular PaaS solutions, while one of the most frequently mentioned self-hosted variant is~Cloud Foundry.

The growth of containerisation technologies introduced another type of service called Container as a Service. Technologies like Docker allowed developers and system administrators to deliberate more clearly on the application requirements and separate it from the~operating system. Solutions such as Marathon, running on top of Mesos, and Kubernetes introduced a possibility to manage and orchestrate containers on self-hosted machines. The services provided by cloud vendors include for example Google's Compute Engine or~Amazon's Elastic Container Service (ECS) or AWS Fargate. With the growing popularity of Kubernetes, dedicated services leveraging that platform emerged, including Amazon Elastic Kubernetes Service (EKS) and Google Kubernetes Engine (GKE).

Each of the described services are next generations of infrastructure outsourcing, which raise the level of abstraction from the development perspective and hand off more and more responsibility related to infrastructure management to the cloud vendor. Despite the fact, for each of the mentioned services the smallest unit of processing is some sort of server application or running application process in the virtual machine or within the container.

Serverless is considered as a next step in the cloud computing progression. The term serverless was one of the first used by Ken Fromm in his paper \cite{KenFromm}. It describes the~notion of architecture migration from monolithic applications running on servers into distributed systems that consist of multiple components, processes and data stores with the goal to perform various tasks and process numerous flows. The serverless architecture enables developers to make a mind shift accordingly. Computing resources can be used as services, which makes it possible to shift thinking from the servers level to the tasks level, taking away the complexity of infrastructure management. The servers are still used underneath, but developers don't need to worry about managing them any longer.

Such an architecture model was leveraged firstly by mobile applications built on top of hosted database solutions, such as Parse (later acquired by Facebook) and Firebase around 2012 (obtained by Google). Nonetheless, the most significant event shaping the serverless architecture was the announcement of AWS Lambda in 2014, altogether with the introduction of API Gateway in 2015. By the middle of 2016, major cloud vendors such as Microsoft and Google embraced the serverless architecture approach and started offering their services for developing serverless applications.

\section{Defining serverless} \label{section:serverless-definition}

Despite the fact that the idea of serverless computing emerged about a decade ago, it~has~been already widely adopted by leading cloud providers. Currently it covers a~range of~technologies, components and cloud services. Nevertheless, there is no clear and concise view on what ''serverless'' is. Various vendors, organisations and research groups tried to~define what the serverless term means for them.

Cloud Native Computing Foundation is the organization working towards standardisation of numerous cloud-related technologies and components. It maintains a sustainable ecosystem for cloud native software by bringing together and collaborating with various members of the cloud community. According to ''CNCF Serverless Whitepaper'' \cite{CNCFServerless}.

\begin{quotation}
Serverless computing refers to the concept of building and running applications that do not require server management. It describes a finer-grained deployment model where applications, bundled as one or more functions, are~uploaded to a platform and then executed, scaled, and billed in response to~the~exact demand needed at the moment.
\end{quotation}

Another definition considering the serverless service capabilities can be found in~a~booklet made by Mike Roberts and John Chapin titled ''What is Serverless?'' \cite{RobertsChapin2017}.

\begin{quotation}
\noindent A Serverless service:
\begin{itemize}
    \item Does not require managing a long-lived host or application instance
    \item Self auto-scales and auto-provisions, dependent on load
    \item Has costs that are based on precise usage, up from and down to zero usage
    \item Has performance capabilities defined in terms other than host size/count
    \item Has implicit high availability
\end{itemize}
\end{quotation}

The cited definitions contain insightful information about features of serverless architecture and capabilities of its components. These can be summarized as follows:

\begin{itemize}
    \item Serverless architecture defines the new model of~developing and executing workloads. The application consists of multiple serverless components configured together to run the business logic within the application code, designed to be executed in a serverless environment.
    \item It does not require to maintain, provision and monitor servers and applications. Serverless does not mean that there are no servers --- the overhead of managing them is handed off to the cloud provider.
    \item Deployment model is more granular. Having the application built from multiple components configured to work together, the deployment can update only selected ones.
    \item Platform is responsible for provisioning and executing the applications. With a large resource pool maintained by cloud provider and the possibility to quickly allocate it, the solution can be scaled automatically to the current load requirement almost instantly.
    \item The cost is proportional to the resource usage. Each of the components involved in performing the computation is billed granularly, with an accuracy to hundreds of~milliseconds or number of executed operations, with no cost when being idle. Executing hundred operations in parallel will cost the same amount of money as~running that workload sequentially.
    \item The performance is not related to the host size. Some of the cloud providers enable customers to choose how much memory and CPU can be allocated for the environment. Nevertheless, the configuration is abstracted from the capabilities of the underlying machine that is used as an execution environment.
    \item The serverless components are built with high-availability and fault-tolerance in~mind. Despite the fact that developers are no longer concerned with servers, the underlying vendor's machines can still fail. When using serverless services we expect that cloud vendors will provide transparent high availability for its services. Although, as developers it may be necessary to handle consequences of some errors and failure occurrences properly.
\end{itemize}

\section{Serverless components} \label{section:serverless-components}

When considering the serverless architecture, it refers to a range of technologies provided by cloud platforms. Two different areas can be distinguished, defining two distinctive components:

\begin{itemize}
    \item \textbf{Backend as a Service} refers to third party services or generic components, capable of replacing some part of a server side application, that was previously developed internally or self-provisioned. It exposes an API which allows for integrating the component with the rest of the application.
    \item \textbf{Function as a Service} is an event-driven execution environment for running application code within stateless and ephemeral containers with strictly limited execution time.
\end{itemize}

Aforementioned components used simultaneously enable developers to build fully-fledged solutions utilising serverless architecture and are offered together within a single cloud platform.
Even though presented areas serve different roles, they share common features and capabilities. These could be listed as follows:

\begin{itemize}
    \item Require no resource management and are entirely provisioned by cloud provider
    \item Utilise the event-driven model for processing
    \item Underlying platform ensures automatic horizontal scaling, high availability and fault tolerance
    \item Billing is proportional to actual usage
\end{itemize}

\subsection{Backend as a Service}

The concept of Backend as a Service (BaaS) gathers various domain-generic, repeatable application components capable of replacing some part of application logic or providing some functionalities. They can be accessed and integrated into developed applications through API defined by its provider.

Taking into consideration most popular requirements of various applications, the majority of them need to store and manage the data. Depending on the requirements, the~information should be stored in a structural way in databases or can be stored regardless of their shape in file storage service. For teams developing mobile or web applications it~is~convenient to rely on some third party components to store and access the data directly from the application. Services like Google's Firebase meet such requirements and give access to the database entirely managed by a cloud vendor. Depending on the complexity of developed product, it may be required to incorporate some more advanced components to process required tasks or flows, reflecting the business logic of application. Mechanisms serving as notification services, exposing some publish-subscribe capabilities for defined events, could be applicable in that case. It is essential to notice that such components are replacing previously self-hosted components such as databases or other data stores, message brokers or similar services responsible for processing data streams incoming from various sources.

Looking closer from the application logic point of view, there are also repeatable functionality implementations that can be extracted and reused across multiple developed applications. Majority of the products will require some features enabling users to manage their identity and associated permissions. Most of the time, the capabilities will be~not only limited to registering and logging users, but it will also include integrations with other services as identity providers. Managing and sending emails can be considered as another functionality that can be extracted into separate component from the code perspective and reused in other applications. Products such as Auth0 (serving as fully featured authorization and user management service) or Mailgun (capable of managing and processing emails) makes it possible to replace entirely the repeatable part of business logic.

Specific components and services that can be classified as Backend as a Services will be~covered in more details in chapter \ref{chapter:serverless-service-providers}, when analysing services provided by leading cloud vendors. All of the mentioned components enable developers to create fully fledged applications and services similar to the solutions built using self-hosted component equivalents. The difference for given components is the fact that they characterise by capabilities of~the~serverless architecture. They are provided by cloud vendors, who take responsibility for managing, provisioning and scaling them depending on the demand. Moreover, the~possibility to replace the repeatable application features by utilising third party services enables developers to iterate faster and shorten the lead time.

\subsection{Function as a Service} \label{chapter:serverless-faas}

The second area refers to Function as a Service (FaaS) that serves as an environment for~executing application code. It introduces a new architectural approach in terms of~developing, structuring and deploying the application logic, which is oriented towards individual tasks and operations.

Mike Roberts briefly described the idea of FaaS \cite{MartinFowlerServerless} based on the definition of~AWS Lambda \cite{AWSLambda}, which is currently one of the most commonly used implementation of~a~Function as a Service model. Based on his summary several main features of FaaS can be~highlighted:

\begin{itemize}
    \item The main idea of FaaS is to run application code without managing servers and application processes. It is a common feature with other approaches like CaaS or PaaS, where the responsibility for managing applications is placed on the cloud vendor. However, the key difference with FaaS is the fact that the function execution time is strictly limited in contrast to long-lived processes existing in aforementioned services.
    \item The functions are invoked and executed on the underlying platform in response to~specific events occurring or coming in the system. Based on that cloud provider handles resource allocation and runs the function code in an ephemeral container, created based on runtime needs. These are destroyed shortly after the event is~processed by the application logic in the function. Together with limited execution time it is a significant architectural restriction for the FaaS model.
    \item Given the fine-grained execution model, horizontal scaling can be easily and automatically handled by the cloud provider. When there is an increased traffic in the system, the platform responsible for executing functions allocates resources to create and run more functions, which will be capable of processing the increased traffic. An~analogous situation takes place when there is no traffic, therefore there is no need to allocate resources for running functions code.
    \item As a consequence of greater granularity of the application code and managing the function execution by cloud provider, the deployment process differs from the traditional system. Each function can be independently packed and uploaded to the FaaS platform, which takes responsibility for executing it.
    \item Most of the cloud platforms do not require to use neither predefined framework nor programming language. Although cloud providers define the list of environments and languages that are supported by the platform, any process that is bundled into the artifact and can be executed from it, is capable of processing the incoming event.
\end{itemize}

Selected aspects of Function as a Service architecture are covered in more details based on ''CNCF Serverless'' whitepaper \cite{CNCFServerless} in the following sections.

\subsubsection{Function lifecycle}

Before analyzing the execution model in more details, it is important to examine the~deployment process accompanying the development of a function. Alongside with providing the function code, the developer is responsible for specifying one or more events upon which function will be triggered. Additionally, metadata defining for example the function version, environmental variables, execution role and other configuration parameters can~be~defined. The function and specification prepared in that way is uploaded to~the~cloud~provider and processed by a dedicated builder entity, resulting with a function artifact (depending on the cloud platform and selected runtime it can be a binary file, container image or a package). Next, it is deployed on a cluster managed by a FaaS controller responsible for provisioning, controlling and monitoring function instances based on incoming events.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{assets/02-serverless/ServerlessDeployment.png}
    \caption{Function deployment and invocation process}
    \label{fig:function-deployment-and-invocation-process}
\end{figure}

Furthermore, the serverless platform may provide additional actions related to~the~function management such as executing, publishing, updating and deleting the function or~its metadata. Also, a particular version of the function can be labeled or aliased, which can come in handy when operating the serverless system on a larger scale. Logs and~statistics are gathered alongside function execution.

The function is executed in an event-driven model and within strictly limited processing duration. The whole process begins when an event triggering a particular function is~dispatched. It is detected and registered by an underlying serverless platform. The~controller, responsible for managing function executions, looks for functions associated with incoming events, gets their code and configuration and allocates an adequate amount of~resources from the managed resource pool. The~new~execution environment is created inside a lightweight, ephemeral container and language runtime for the function is bootstrapped. When the environment is ready, the triggering event is redirected and processed by~the~application logic included in the function code.

The results of computing are sent back to the event dispatcher. Meanwhile, the function can create new events during its execution. The computing duration is limited by~the~majority of service providers up to a few minutes, after that the computation is~completed with timeout. Finally, the lightweight container including the execution environment is~destroyed.

Most of the providers delay the container deletion for longer than a couple of minutes due to optimisation related with reusing the same container instance when the next event occurs in the system. Reusing an already initialised execution environment is called a~''warm~start'' and allows to reduce the startup latency related to resource allocation and runtime bootstrap. The opposite situation takes place when the new container instance needs to be initialised and the host process needs to be created. Most of the time it~requires additional time, impacting the request processing duration and it is called a~''cold~start''.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{assets/02-serverless/ServerlessExecution.png}
    \caption{Function execution process considering ''cold~start'' and ''warm~start''}
    \label{fig:function-execution-process}
\end{figure}


\subsubsection{Function environment} \label{section:serverless-function-environment}

The characteristic of the function environment has been already drafted during description of the function lifecycle. Due to improvements in the software virtualisation field, cloud vendors can benefit from efficient and elastic management of large resource pools. It~enables vendors to allocate lightweight and ephemeral containers efficiently, serving as~an~execution environment. Each of them is initialised to executes code of one of~the~functions at a time and it is destroyed shortly after, releasing the resources to the common resource pool. Even though containers can be reused for the optimisation purposes when handling subsequent events occurring in the system, it~is~not~guaranteed by the~serverless platform and should not be taken for granted by developers, that some data will be~preserved for~subsequent invocation.

Such an architecture leveraging stateless containers allows for automatic horizontal scaling. When multiple concurrent events occur within the system, the platform is capable of creating a separate container to process each of them independently. In order to handle spikes of traffic effectively, quick provisioning of the containers and reducing their startup latency is required and it is a purpose of many research works and improvements made by both researchers and cloud vendors

As mentioned before, ephemeral containers are dismissed shortly after the execution alongside with their internal state. For some types of computing it would be desirable to~preserve that state. To address that issue, external components need to be involved to~persist the data. Nevertheless, it introduces the need to communicate with some external service and it is often associated with additional delays resulting from the communication overhead.

\subsubsection{Function invocation} \label{section:serverless-function-invocation}

The serverless architecture utilises an event-driven processing model. The developer's task is to define the configuration that maps events coming to the system with appropriate functions. Each of dispatched events can trigger one or more functions as well as each function can be invoked by one or more predefined events --- there is a many-to-many association between functions and event sources. The mapping can also refer to a particular version of the function or alias, which can greatly simplify the~deployment process by replacing the function code for a given alias without modifying the configuration.

Various data sources can~be~divided into several categories, distinguishing among the~others:

\begin{itemize}
    \item Endpoint Services - Most of the time associated with API Gateway components, which introduces mapping between request coming from APIs (such as REST or~WebSocket) and associate them with corresponding functions.
    \item Storage Services - Category includes numerous BaaS components provided by a cloud vendor like databases, file storage or cache services. Events can be emitted based on~operations performed on the data such as creation, deletion or modification~of~it.
    \item Messaging Services - Services providing mechanisms for data streaming, message brokers or various services sending notifications.
    \item Scheduled events - That category includes services capable of emitting events periodically at a given time or at a selected interval
\end{itemize}

Based on the use case, several invocation types can be differentiated:

\begin{itemize}
    \item Synchronous Request - Includes cases when the client sends a request and waits for~the~response. It is used most frequently for HTTP requests.
    \item Asynchronous Message Queue Requests - Refers to events emitted from various data sources, when messages are published to some exchange that later distributes them to other subscribers. Messages are delivered exactly once without strict ordering.
    \item Event Streams - Are based on streams of messages, logs or files. Sequence of record is most of the time partitioned into several shards.
    \item Batch Jobs - Refers to jobs that can be split into smaller tasks and processed in~parallel by multiple functions. The entire process is completed when all subsequent tasks are finished.
\end{itemize}

\section{Benefits and challenges} \label{chapter:serverless-benefits-and-challenges}

The emergence of serverless architecture has met with great interest from various software architects, developers and companies that noticed numerous advantages of this approach. In addition to the promise of significant cost reduction, the development and operational opportunities and reducing time to market are just a few of the benefits that serverless introduces.

Nevertheless, the serverless architecture has also many disadvantages, inherently connected with its nature. Some of them have been addressed by various cloud vendors working towards improving their services and mitigating the problems. Despite the fact that many companies have already adopted developing services in the serverless paradigm, the technology is still not fully mature. There is a lot of research going on in various areas related to serverless computing by both researchers and cloud service providers.

Based on the reports and articles discussing the advantages and drawbacks connected with the serverless paradigm \cite{MartinFowlerServerless} \cite{BerkeleyServerless} \cite{ServerlessComputingSurveyOfOpportunitiesChallengesApplications} \cite{LeveragingServerlessCloudComputingArchitectures}, the benefits and challenges of the architecture have been presented below, with the latter divided into three distinctive categories.

\subsection{Benefits}

\subsubsection{Reduced development and operational cost} \label{chapter:serverless-reduced-development-and-operational-cost}

Serverless is essentially another step in the process of infrastructure management outsourcing, similar to IaaS and PaaS. In this approach, developers instead of requesting resources, provide an artifact including code to be executed and the cloud platform is responsible for provisioning the resources and executing the application logic, based on defined triggers' configuration. The responsibility of managing the servers, databases and application execution is transferred to~the~cloud provider \cite{BerkeleyServerless}. The favourable and competitive prices are available due to economy of scale, in which one vendor is running thousands of~predefined services, effectively sharing the infrastructure among the customers.

The labour cost connected with the serverless architecture is also reduced, because there is less work related to managing the serverless solution, compared to the self-hosted alternative. There is no need to setup and maintain hardware as well as restore it~to~proper condition in case of failures --- new resources can be allocated and be ready to~work with, within a moment from requesting it. The development cost is also reduced due to the frequent usage of BaaS components, replacing the application elements that were previously developed in-house, while now can be incorporated with the application logic. An~example of such approach is aforementioned Auth0 providing the authentication capabilities or~Firebase, enabling client applications to directly communicate with server-side databases accordingly, providing proven authentication mechanisms for different types of~users and~removing much of the database administration overhead \cite{MartinFowlerServerless}.

\subsubsection{Autoscaling with proportional cost} \label{chapter:serverless-autoscaling-with-proportional-cost}

The serverless billing model refers to paying proportionally to the time resources are used, instead of calculating the cost based on the size of cloud resources as in IaaS or~PaaS offerings. By tracking the load with a greater fidelity, scaling up quickly in case of~increased demand and scaling down in the absence of it, customers are actually charged for the time the code was executed rather than the resources used to execute their software \cite{BerkeleyServerless}.

Additionally, with the greater granularity, only the components affected by increased demand can be scaled accordingly, compared to the conventional computing. The serverless processing is characterized by the instant horizontal scaling, which is an ability to parallelize heavy workloads almost instantly on demand and deprovisioning resources shortly after, that is an automatic process handled entirely by the cloud provider. It enables companies to shift from the capital expense to the operational expenses when running their software, which removes the need to invest beforehand in costly hardware before the~application or service is created and deployed \cite{LeveragingServerlessCloudComputingArchitectures}.

The cost reduction is the most visible when the service has to process the occasional or~inconsistent traffic. In the first case, the processing will be executed based on~the~event, billed accordingly to execution time and not paying for idle, which is significantly more efficient compared to the self-hosted solution, in which some server is running the application all the time. When running the application in the latter case, it~may~be~necessary to have enough hardware to handle the highest demand to ensure the running service is~capable of~handling all the requests. With the serverless solution the cloud provider is~responsible for scaling to handle the demand. The customers pay~only~for~the additional time hardware was computing to satisfy the higher traffic. Comparing~to~provisioning virtual machines, there is no risk of overprovisioning (when demand is handled on time, but~the~resources are not fully utilised) or underprovisioning (when the average processing capacity is optimised, but the highest traffic may not be handled on time or even not~at~all). These examples are~deliberately picked to showcase the significant cost savings of~serverless, but~on~the~other hand when the traffic shape is making a good utilisation of running servers, the cost of~using serverless technologies can be higher. Lastly, considering the~serverless model, any performance optimisations making the function execution shorter or~reducing the number of requests to some other BaaS component can accordingly reduce the cost \cite{MartinFowlerServerless}.

\subsubsection{Easier operational management} \label{chapter:serverless-easier-operational-management}

Considering the scaling is automatically handled by the cloud vendor, there is no need to~hire the qualified administrators to manage and scale the application and make sure that the service is running properly, which leads to further cost reduction. The packing and deployment process for serverless solutions is also simplified, compared to deployment of~new versions of software to the servers. There is no need to manage some scripts or~specified software responsible for performing the deployment, the serverless solution can be packed, zipped with appropriate configuration and deployed to the cloud, where the cloud vendor handles the rest of the process. In the fully serverless solutions the~system administration role can be effectively minimised by the serverless platform when embracing the proper process automation \cite{MartinFowlerServerless}.

\subsubsection{Development opportunities} \label{chapter:serverless-development-opportunities}

Serverless solution is appealing, due to the possibility to reduce the cycle time. The focus of development can be put on the business logic and new features instead of managing the~infrastructure.

The serverless architecture brings new architectural opportunities and provides some interesting architectural properties. For example, the automatic horizontal scaling brings yet another benefit --- the software architects and developers no longer need to think about designing the solution to ensure the scalability, since it is provided out of the box by the cloud platform. Similar situation can be noticed for the implicit failover. There is no need to run another instance to pick up the computation once the first one fails. In contrast, FaaS handles implicit failover by retrying the execution on newly provisioned functions once the initial on crash \cite{LeveragingServerlessCloudComputingArchitectures}.

The cloud platform provides various BaaS components, enabling to incorporate and integrate them with the developed solution. They offer various capabilities not only related with authentication, storing data or exchanging messages in a publish-subscribe manner, but also provide some more sophisticated services including documents and image processing, generating transcriptions or incorporating machine learning for advanced prediction. This gives the opportunities for developers to look at a vast area of new possibilities with a matter of integration and configuration of some of the services.

It is especially beneficial for agile teams, gearing towards lean and agile processes by~reducing time to market, which is understood as the time from an idea until the~product is~available for the customers. When having the better granularity of code, without~the~need to manage the infrastructure, the new version of a service can be released more frequently, moving towards the idea of continuous deployment. Along with the granular billing model the companies can try out new solutions with minimal cost and friction. The~new~experiments can be deployed within a moment since the development is completed, enabling~the~product owners to set the mindset of continuous experimentation. The proof of concept feature with the limited traffic will cost proportionally less or could be even free if the resource utilisation fit into the free tier provided by some of the cloud providers \cite{MartinFowlerServerless}.

\subsubsection{Greener computing}

The growth of awareness about environmental problems has influenced the way the data centers are built. To fulfill their energy requirements cloud providers host their data centers near the renewable energy sources to reduce the fossil-fuel emission. Contrary to the typical business and enterprise data centers, in which some of the idle servers are~powered up, consuming large amount of energy and impacting environment.

Cloud infrastructure partially mitigates that problem, because the companies are renting the computing resources based on the demand, rather than provisioning the servers on~their own, especially when these are run without adequate awareness about the~capacity management. When using IaaS, PaaS or self-hosted solutions, most frequently the users are responsible for scaling the services, preferably overprovisioning the resources, which leads to an inefficient energy utilisation. The cloud provider takes the responsibility for~the~serverless solutions by provisioning the compute resources and handling the~capacity decisions to fulfill the needs, leading to far more efficient resource and energy utilisation across data centers and reducing the environmental impact \cite{MartinFowlerServerless}.

\subsection{Challenges related to the nature of serverless architecture} \label{chapter:serverless-challenges-related-to-the-nature-of-serverless-architecture}

\subsubsection{Function state management}

As mentioned before, the FaaS is effectively stateless. Due to that fact it faces a significant limitation when it comes to the local state. It should be assumed that the state from one invocation will not be available in subsequent invocation of the same function, which is connected with the lack of control over the ephemeral container function it~is~running in. To share state between subsequent function execution, some external component like database, cache or external object storage is required to preserve the data, which introduces significant communication overhead, leading to latency increase \cite{MartinFowlerServerless}

This highlights that some types of computation, relying heavily on fine-grained state sharing, may not be suitable for the serverless model. Two distinctive types of storage needs to be addressed. First of them is a low-latency ephemeral storage, enabling to transfer data between functions and maintain the application state during application lifetime. Once processing is finished, the state can be discarded. To achieve this some in-memory cache with optimised network and low latency operations can be considered. Nevertheless, the main challenge is related to providing automatic scaling, allocating and deprovisioning resources as well as ensuring access protection along with performance isolation. The~second type refers to durable storage, as a long-term data storage with mutable semantics of~a~file system. It should also be transparently provisioned, ensuring proper level of~isolation, security and performance predictability, but contrary to ephemeral storage the~data should be durable and its removal should be explicit along with maintaining low cost \cite{BerkeleyServerless}.

\subsubsection{Function communication and data transfer}

The service built using the serverless architecture is essentially a composition of many functions and BaaS components working together to provide the desired functionality. To~achieve this, functions need to communicate and exchange the data. In other cloud services communication can be attained through network addressing, but in serverless architecture functions are ephemeral and anonymous. The function-level addressing is~not~available, and they need to communicate through intermediate storage or messaging service, introducing additional latency, which can be pretty expensive with finer-grained communication patterns. Additionally, the fact that functions can be allocated and load balanced according to the current utilisation of~resources in the data center, impacts the~performance when the data needs to be transferred to the function. Due to that fact, the data caching in a serverless environment can be more difficult to be implemented in~an~effective way, since the functions are placed and executed independently \cite{ServerlessComputingSurveyOfOpportunitiesChallengesApplications}.

Some of the communication patterns known from machine learning or big-data analysis software, like broadcast and aggregation, require sending more messages and~can~be~less performant when implemented in a serverless architecture. Compared to the software running on virtual machines, the tasks can share a copy of the received data and perform local aggregation to limit the message overhead and amount of data being sent. Moreover, the serverless component utilises most frequently some intermediate component working in~a~producer-consumer pattern to send the data, which introduces additional communication delay. Due to lack of addressability, the functions are unable to communicate directly, for~example calling one another when the data is present or coordinate some distributed operation \cite{BerkeleyServerless}.

To address that problem, cloud providers could enable developers to assign the group of~functions to the same machine instance, reducing the data exchange overhead or~compute the communication graph to place functions efficiently, but it would reduce the flexibility of cloud providers and data centers utilisation. Some of the offerings, such~as AWS~Step~Function or Azure~Durable~Functions, try to address the function orchestration problem by~running a sequence of lambda functions as event-driven workflow and~efficiently maintain the application state between the subsequent invocations.
Another approach proposed by various practitioners considers sort of a hybrid solution to address the problem of~externalized state constraint and lack of function addressability. The low-latency application can be run as the regular, long-running server handling the~requests and keeping the~context in local memory. Later, the process can hand off the~fully contextualized request to serverless functions, which can be executed concurrently to~perform some computation without the need to lookup for external data.

\subsection{Cloud platform and vendors challenges} \label{chapter:serverless-cloud-platform-and-vendor-challenges}

\subsubsection{Vendor dependency} \label{chapter:serverless-vendor-dependence}

As with any outsourcing technology, some control of the system is given up to the service provider, which is also the case with the serverless paradigm. The cloud vendor can put some constraints on how the clients use their services in form of unexpected limits or API changes to be more likely to deliver the reliability on its side. Similarly, when using BaaS components, developers no longer need to implement and maintain them, but it is not guaranteed that the external services will be running without some issues or unexpected failures. If the cloud platform would be to satisfy the needs of hundreds of customers or~the~smaller group, it will most probably choose the majority to ensure accountability of~services \cite{MartinFowlerServerless}.

\subsubsection{Vendor lock-in}

The cloud provider selection is a significant decision when building some service using the serverless architecture, not only due to their offerings, but also due to differences in~their services implementation that make the further shift harder or even almost impossible without major changes. When taking a closer look at the function invocation semantics, each of them depicts the different interface and events triggering it. The divergence also occurs on the level of BaaS components, which expose various behaviours and API that may even require to change the architecture solution in some cases. Moreover, operational tools related with deployment, logging, monitoring and configuration management will most probably differ and require migration.

When migrating the serverless solution from one of the cloud providers to another one, some parts of the system can be translated more easily, but others can have a significant impact on the whole architecture of the developed solution. For example porting of some function code between cloud platforms will not be possible without migrating other chunks of the architecture. Some companies adopt multi-cloud approaches leading to developing and operating the application in a way that is agnostic to the cloud vendor. Most frequently it is a more costly solution, which makes it impossible to apply benefits, optimisations and more specialised components provided by the cloud vendor \cite{MartinFowlerServerless}.

\subsubsection{Startup latency and platform improvements} \label{chapter:serverless-startup-latency-and-platform-improvements}

Serverless functions have much lower startup latency than the application executed on~the virtual machines, but because of the frequency of using new function instances, the low startup time is crucial to provide efficient processing. The function startup time consists of~scheduling and allocating the resources to run the function, establishing the environment for code execution and initialising the libraries and data structure to run the function code.

When the function is executed for the first time after a longer period of inactivity or~when a new version is deployed, the function bootstrapping process will consist of~all the steps forming aforementioned ''cold~start''. Providers have already noticed that resources and environment of the function containers can be reused to save some of the bootstrap time. Nevertheless, the most noticeable latency related to the full function setup has~a~significant impact on the service performance from the user point of view \cite{BerkeleyServerless}.

Different approaches are currently available to mitigate that problem, but~they~are~coming with an additional cost. The long-running instances can handle low-latency applications well, because they are always running and ready to serve the traffic. Similarly, function can be pre-warmed regularly to ensure the resources and environment is ready to satisfy the incoming request. AWS Provisioned Concurrency is one of the dedicated extensions of the AWS Lambda service, while Serverless Framework includes some plugin, responsible for registering scheduled events that keep functions warm.

Another factor limiting the serverless function execution is constrained execution duration. Various FaaS offerings from the biggest cloud providers limit the execution time to elastically manage their resource pool. However, the cloud vendors could also increase the transparency of services and provide more clear expectations towards their platforms to increase the degree to which customers can rely on them \cite{MartinFowlerServerless}.

\subsubsection{Multitenancy problem} \label{chapter:serverless-multitenancy-problem}

To achieve efficient resource utilisation, multiple cloud functions from different applications and customers are executed on the same virtual machine, enabling the cloud platform to~provide affordable services. Cloud vendors are doing their best to provide a~proper level of~isolation between different tenants and application execution. Most~of~the largest providers developed mature technology to ensure the high quality of their services, but~for~other less mature solutions, some problems can be noticeable. Among the most common issues robustness (error in customerâ€™s software causes failures of other), performance (one~customer takes majority of the machine resources causing others to slow down) or even security (seeing data of other customers) can be distinguished \cite{MartinFowlerServerless}.

\subsubsection{Security concerns} \label{chapter:serverless-security-concerns}

Serverless architecture opens a large number of security questions, taking into consideration the attacks surface of serverless composition which is not fully researched yet. On~one~hand, the cloud providers should ensure proper security level of their services, by monitoring them and patching eventual vulnerabilities. However, executing the computation within a shared resource pool extends the area of potential attacks, when some process breaks out from the ephemeral function container \cite{LeveragingServerlessCloudComputingArchitectures}.

To address this problem, different tenants and applications could be physically isolated, but it can impact the resource allocation and the startup time optimisation. The~greatest challenge is to provide a proper function level sandboxing, while maintaining the~short startup time enabling a shared environment between repeated function invocations. It~could be~possible by snapshotting the instance locally or using lightweight virtualisation technologies, and it is a subject of active research and improvements \cite{BerkeleyServerless}.

Another security concern takes into account the direct access to the services directly from the client applications, which requires additional attention, since there is no protection of the server application available in traditional approach. Utilising various services from different providers makes the area of potential vulnerabilities larger and establishes multiple possible ways to breach into the system. The communication between them needs to be properly integrated and protected.

When building some service utilising different functions and components it will require cooperation between them to perform the processing. Each of the functions should have granular access policies, granting only the required permissions to the BaaS components used by the function. Maintaining and validating the security and~access policies is~not~a~trivial task, especially when the number of services, including its components and~access patterns, is increasing overtime \cite{MartinFowlerServerless}.

\subsection{Development and operational challenges} \label{chapter:serverless-development-and-operational-challenges}

\subsubsection{Development and debugging} \label{chapter:serverless-development-and-debugging}

The serverless computing introduces a relatively new approach to developing services and~with~the lack of knowledge and proper modeling paradigm it can lead to many development approaches, reducing the quality of service and complicating the collaboration between developers. New ideas and patterns are created and researched to utilise serverless architecture effectively, which leads to high demand for practitioners and architects aware of the best practices and providing reference architectures \cite{ServerlessComputingSurveyOfOpportunitiesChallengesApplications}.

Developing the fully serverless solution introduces additional difficulties due to inability to replicate the cloud environment locally. Some of the cloud vendors provide tooling to~execute the functions locally, for example AWS Serverless Application Model enables to~execute functions locally and pass the event payload saved beforehand. Altogether with the execution, some tools enable function debugging, while Azure even makes it~possible to run local debugging for functions triggered by remote events. Nevertheless, to verify behaviour of other services it is essential to deploy the service and verify its~behaviour in~a~cloud environment. The idea of distributed monitoring, which enables tracing the~flow of~a~single request across multiple components, is covered by platform services such as Amazon X-Ray and other third party offerings.

Over the recent years, the ecosystem of serverless tooling significantly evolved, providing various products and services, which helps with the development and operational aspects of managing serverless applications and services. The process of deployment and bundling improved with the introduction of Serverless Framework, AWS SAM and AWS~Cloud Development Kit, which allow to define the architecture using many popular programming languages. Lastly, the serverless tooling helps with operational aspects enabling various higher level releases approach, supporting traffic shifting, A/B testing, blue-green deployments or canary releases, which are essential when releasing complex, distributed application that consist of hundreds of functions \cite{MartinFowlerServerless}.

\subsubsection{Testing} \label{chapter:serverless-testing}

The unit testing of serverless functions, which are initially pure functions that are mapping input to the output, is fairly simple. Contrary to the integration testing, because most functions use various BaaS components or other external services creating a dependency in tests. Some of the vendors supply mocked implementations or stubs that can~be incorporated into tests and imitate the BaaS behaviour. Nevertheless, the idea giving the~most confidence is to deploy the service into the cloud environment and conduct some end-to-end tests to verify the quality of software.

The ideal and most appealing approach would be to create a suite of automated integration tests, deploying the functions and infrastructure configuration to the cloud as~part of the integration pipeline to verify whether it is working as intended. However, running such tests creates additional cost with every execution, due to resource usage for~processing the test data. It may also require more work compared to writing integration tests for~regular services created as stateful applications. 

One radical change that could be embraced, is the idea of testing in production and~monitoring-driven deployment that is related to switching subset of the traffic to~the newer version and comparing the observed behaviour with the previous one \cite{MartinFowlerServerless}.

\subsubsection{Monitoring and observability} \label{chapter:serverless-monitoring-and-observability}

Monitoring the service created by utilising the serverless architecture can be more difficult due to the ephemeral, granular and distributed nature of the processing. Aforementioned distributed monitoring is especially desired to trace the flow of a request not only to verify if the application works correctly, but also to give more insight into performance aspects directly correlated with the cost \cite{LeveragingServerlessCloudComputingArchitectures}.

Most cloud vendors provide some tooling to monitor the system and there are many third party offerings helping with achieving better observability in this area. Despite the fact that more of the operational context related with infrastructure management is~handed off to the cloud vendor, there is still plenty of administration work with ensuring monitoring, proper security level and verifying that the appearance of alarms when crossing some of the established limits, does not affect the proper service execution. Introducing various checks in the deployment process can ensure that the service quality is preserved. Techniques like preemptive load testing and chaos engineering can help simulate various critical situations and verify that the system is able to cope with them \cite{MartinFowlerServerless}.

\section{Cloud providers} \label{chapter:serverless-service-providers}

Since the announcement of AWS Lambda in 2014, other companies followed the footsteps of Amazon Web Services and started offering their solutions for building serverless applications and services. Currently, several major cloud vendors provide large variety of~services and functionalities forming complete serverless platforms. Along with the public cloud expansion, couple of open-source projects and platforms emerged as an alternative, allowing developers to use FaaS on on-premise hardware and in a private or hybrid cloud. The~variety of cloud vendors offerings is significant, some of them expose the fully-fledged platforms with numerous BaaS components that can be integrated together, others provide the FaaS along with the possibility to host the applications in containers, virtual machines or incorporate serveless processing, along the statically hosted websites or cloud-managed database products. When selecting the cloud providers it is essential to consider several factors, like industry adoption, maturity and number of services, ease of~integration as~well as cost of the services. According to the survey conducted in June~2020 by Cloud~Native~Computing~Foundation (CNCF) \cite{CNCFServerlessSurvey2020} the market share of FaaS platforms is~presented in~Figure \ref{fig:hosted-serverless-platform-share-survey}

\begin{figure}[h]
    \begin{tikzpicture}
        \begin{axis} [xbar = .05cm,
            bar width = 12pt,
            ytick = data,
            enlarge x limits = {value = .15, upper},
            symbolic y coords={AWS Lambda,Google Cloud Function,Azure Function,Alibaba Cloud Function,CloudFlare Workers,IBM Cloud Function,Oracle Function,Netlify Functions},
            xticklabel={\pgfmathprintnumber\tick\%},
        ]
        
        \addplot coordinates { 
            (55,AWS Lambda) 
            (27,Google Cloud Function) 
            (24,Azure Function)
            (5,Alibaba Cloud Function)
            (3,CloudFlare Workers)
            (3,IBM Cloud Function)
            (2,Oracle Function) 
            (1,Netlify Functions) 
        };
        \addplot[only marks, 
            nodes near coords,         
            every node near coord/.append style={xshift=25pt,yshift=0pt,anchor=east,font=\footnotesize},
            point meta=explicit symbolic,
            ] coordinates { 
            (55,AWS Lambda) [$55\%$]
            (27,Google Cloud Function) [$27\%$]
            (24,Azure Function) [$24\%$]
            (5,Alibaba Cloud Function) [$5\%$]
            (3,CloudFlare Workers) [$3\%$]
            (3,IBM Cloud Function) [$3\%$]
            (2,Oracle Function) [$2\%$]
            (1,Netlify Functions) [$1\%$]
        };     
        \end{axis}    
    \end{tikzpicture}
    \caption{Hosted serverless platform usage according to the CNCF survey \cite{CNCFServerlessSurvey2020}}
    \label{fig:hosted-serverless-platform-share-survey}
\end{figure}

\textbf{Amazon Web Services}, \textbf{Microsoft Azure} and \textbf{Google Cloud Platform} are distinguished as three providers with the biggest market share. Their services are classified into categories and described in more details, altogether with other vendors and companies providing their services in the serverless computing field.

\subsection{Amazon Web Services} \label{serverless-amazon-web-services}

As previously mentioned, Amazon was the company that pioneered the field of serverless computing. Over the years, it established the dominant market position, leading in the number of available services, characterized by high quality and undergoing constant innovation. AWS is an enterprise ready vendor, highly focused on the public cloud sector, providing most comprehensive network infrastructure and data centers.

Moreover, it comes up with rich collection of advanced tools. CloudFormation and AWS Cloud Development Kit enable developers to manage the infrastracture, utilising the Infrastracture as a Code (IaaC) paradigm. Furthermore, the AWS Serverless Application Model (SAM), that efficiently integrate with other AWS services, helps with developing, building and testing the created software. Besides, the essential services necessary to develop serverless applications (described below in more detail based on the official documentation \cite{AWSServerlessOffering}), AWS offers a wide range of services oriented towards artificial intelligence and machine learning that allow to train and deploy machine learning models, operates on documents, images or speech. Furthermore, AWS provides services capable of connecting and cooperating with various IoT devices, process multimedia or~help with managing business processes.

The AWS pricing model is considered as a major difficulty when it comes to accurately estimate the cost of running the service, but most frequently the variety and maturity of~services and tooling counterweight this downside.

\begin{enumerate}
   \item Compute
   \begin{itemize}
       \item AWS Lambda --- First FaaS offering available on the market, that allows to~execute the function without provisioning and managing the servers, automatically scaling the solution by running the code in a new instance in response to an event. AWS Lambda supports natively Node.js, Python, Java, C\#, Go and Ruby as execution environments, with a possibility to incorporate custom runtimes or container based environments, charging for the execution with the~millisecond granularity and ensuring consistent performance by enabling Provisioned Concurrency.
       \item AWS Fargate --- Serverless compute engine for containers, eliminating the need to manage the servers, choose instances and scale the cluster capacity, providing appropriate level of isolation and security.
       \item Lambda@Edge --- Enable to run the Lambda code at an AWS location closer to the users of the application, utilising the Amazon CloudFront as Content Delivery Network (CDN) to reduce the latency and improve the performance.
   \end{itemize}
   \item Data Store
   \begin{itemize}
       \item Amazon Simple Storage Service (S3) --- Storage service for objects, offering high data availability, scalability and performance. It provides the storage of~a~wide range of data for different use-cases, such as application data, backups, data lake, websites and other assets, ensuring their durability.
       \item Amazon DynamoDB --- Flexible, scalable and distributed key-value and document database, providing high performance and low-latency data access. Enables data caching, cross-region replication, fault-tolerance and data encryption, being a suitable solution for web and mobile applications.
       \item Amazon Aurora Serverless --- Autoscalable and fully managed configuration for~Amazon Aurora, which is a relational database compatible with MySQL and PostgreSQL, enabling higher performance and availability.
       \item Amazon RDS Proxy --- Fully managed and highly-available database proxy for~Amazon RDS, which is a service that provides hosting and scaling for other relational databases.
       \item ElastiCache --- In-memory data store, compatible with Redis and Memcached suitable for data intensive applications with high-throughput and low-latency data access.
   \end{itemize}
   \item Network and Content Delivery
   \begin{itemize}
       \item Amazon API Gateway --- Managed service, enabling to expose APIs and connect with other AWS services, providing real-time two-way communication via~REST or WebSocket API, billed accordingly to usage.
       \item AWS AppSync --- Another fully-managed and scalable service, capable of defining and handling the two-way communication using GraphQL API as well as the heavy-lifting and communicating with other AWS services to store and sync the data.
       \item Amazon CloudFront --- Fast, secure and programmable Content Delivery Network (CDN) hosting the data such as videos, images or applications, utilising the AWS edge network location to make the service globally scalable and accessible.
   \end{itemize}
   \item Application Integrations
   \begin{itemize}
       \item Amazon Simple Notification Service (SNS) --- fully managed publish-subscribe service enabling high-throughput, many-to-many messaging for communication between applications, microservices and application-to-person messaging.
       \item Amazon Simple Queue Service (SQS) --- message queueing service, allowing to~decouple components of the distributed systems, available in two types: standard (offering high-throughput and best effort ordering) and FIFO (designed for ordered messages delivered exactly once).
       \item Amazon EventBridge --- Scalable serverless event bus, enabling to integrate the~incoming messages from other SaaS offerings with the AWS infrastructure.
       \item AWS Step Functions --- Serverless function orchestrator, allowing to combine AWS Lambda functions into workflows based on business processes, visualising them and maintaining the application state between execution.
   \end{itemize}
   \item Analytics
   \begin{itemize}
       \item Amazon Kinesis --- Offers key capabilities of scalable and fully-managed event streaming service, processing and analyzing real-time video, audio and other data streams instantly, without necessity to collect the data.
       \item Amazon Athena --- Interactive and managed query service for Amazon S3 based on predefined schema, using standard SQL syntax to quickly analyze large-scale datasets
   \end{itemize}
   \item Security and Identity
   \begin{itemize}
       \item AWS Identity and Access Management (IAM) --- Required to manage users, groups and their access to AWS services and resources in a secure way, offered without additional cost.
       \item Amazon Cognito --- Provides authentication service and identity management that can be easily incorporated with various clients solutions on different platforms.
   \end{itemize}
   \item Development Tools
   \begin{itemize}
       \item Amazon CloudWatch --- Service providing application monitoring and observability, gathering logs, metrics and capturing events within the AWS resources. Enables to analyse the environment behaviour, troubleshoot issues and take automate actions based on numerous indicators.
       \item AWS X-Ray --- Tool that allows to analyze and debug distributed application behaviour across multiple services based on the request tracing, gathering the~execution metric to identify the application issues and performance bottlenecks, available for both development and production applications.
       \item AWS Amplify --- Suite of tools and services, helping developers build efficient and scalable applications for web and mobile platforms, providing possibilities to deploy the static sites, easily manage content or configure the application backends with authentication and data storage.
       \item AWS CodeStar, AWS CodePipeline, AWS CodeBuild, AWS CodeDeploy --- Set~of tools helping with the automation, continuous integration and deployment workflows for various applications.
   \end{itemize}
\end{enumerate}

\subsection{Microsoft Azure}

Microsoft is the second from the biggest three vendors that started offering its serverless computing services in 2017, by integrating them into the Microsoft Azure platform. It~also provides a vast number of services, giving a more flexible and configurable runtime engine, supporting more programming languages.

When investing in the serverless field, Microsoft decided to repurpose its existing proprietary software to be available and greatly integrated with the cloud. Microsoft Azure is eager to cooperate with various enterprise companies, especially using their software. Contrary to the AWS, Azure platform can more effectively interoperate with customers' data centers, enabling them to the gradual migration of on-premise software or operate in a hybrid cloud model. Azure platform also provides some powerful DevOps tooling and numerous services, integrating machine learning and artificial intelligence, exposing among the others cognitive services, chatbots and document, images and video analysis and recognition.

Nevertheless, customers frequently are not satisfied with the Microsoft Azure complex pricing model, due to complicated software licensing options that are hard to understand without outside support. Moreover, some of the services are considered less enterprise-ready, due to issues with quality of these services, technical support and lacking documentation or when managing and configuring some of them outside of the Azure platform.

The current serverless offering of Microsoft Azure is presented in more detail, according to the information available on the vendor website \cite{AzureServerlessOffering}.

\begin{enumerate}
   \item Compute
   \begin{itemize}
       \item Azure Functions --- FaaS offering from Microsoft, integrating with other services, executing in an event-driven manner and autoscaling based on demand. It provides tools for building and debugging functions locally, supporting implementations in .NET Platform (C\#, F\#), Java, Node.js (JavaScript and~Typescript), Python and PowerShell, billing the execution on a per second basis.
       \item Azure App Service --- Fully-managed platform for building, deploying and scaling web applicationsm written in .NET, Node.js, Java, Python and PHP, running in Windows or Linux containers, integrating with other services from Azure platform.
       \item Azure Kubernetes Service --- Highly-available and secure managed Kubernetes service, automatically provisioning serverless infrastructure based on the traffic, utilising open-source tools like Virtual Kubelet for provisioning nodes and~KEDA for event processing from various event sources.
   \end{itemize}
   \item Data Store
   \begin{itemize}
       \item Azure Blob Storage --- Scalable, secure and durable object storage, capable of~storing a large amount of unstructured data objects, suitable for cloud-native and mobile apps. It provides high availability and geo-replication, generating events pushed to other Azure services upon data changes.
       \item Azure Cosmos DB --- Fully-managed, globally distributed and multi-model NoSQL database service, guaranteeing low-latency data access and scalability, exposing APIs for SQL, MongoDB and Cassandra.
       \item Azure SQL Database --- Family of SQL cloud databases, providing optimized performance, data durability, backups capabilities and adapting to requirement changes.
       \item Azure Cache --- Managed in-memory data store, which can be utilised as~caching layer, providing high-throughput and low-latency operation time, scaling according to demand with geo-replication and Redis capabilities.
   \end{itemize}
   \item Network and Content Delivery
   \begin{itemize}
       \item API Management --- Service enabling API management across cloud and on-premise environments with unified management experience, focused on security and observability with fine-grained data exposition rules and integration with other services.
       \item Azure Content Delivery Network --- Secure and reliable Content Delivery Network (CDN), greatly integrated with other services from Azure platform, ensuring proper security level and analytics features.
   \end{itemize}
   \item Application Integrations
   \begin{itemize}
       \item Azure Event Grid --- Service handling the message routing from various event sources, working in a publish-subscribe model, ensuring scalability and high-reliability.
       \item Azure Event Hub --- Managed, scalable and geo-replicable real-time data streaming service, enabling to build dynamic data pipelines, capable of seamless integration with other Azure services.
       \item Azure Service Bus --- Reliable and scalable messaging services for a cloud, enabling to build communication between decoupled application components and~on-premise systems, providing various messaging models and offline delivery.
       \item Logic Apps --- Service enabling developers to build various workflows within containerized environments, integrating external services and enterprise SaaS offerings along with the Azure platform components.
       \item Azure Durable Functions --- An extension for Azure Functions, enabling them to execute stateful computation in a serverless environment by utilising the~Orchestrator that defines the state flow between subsequent functions.
   \end{itemize}
   \item Analytics
   \begin{itemize}
       \item Azure Stream Analytics --- Serverless real-time analytics, enabling to build streaming pipelines with similar SQL-like syntax, integrating with other platform services including artificial intelligence for more sophisticated use-cases.
   \end{itemize}
   \item Security and Identity
   \begin{itemize}
       \item Azure Active Directory --- Service enabling identity management, authentication and authorization capabilities for end users. Enhancing it with single sign-on to multiple SaaS applications, multi-factor authentication functionalities and integration with external identity providers.
   \end{itemize}
   \item Development Tools
   \begin{itemize}
       \item Azure Monitor --- Fully managed and scalable monitoring offering, integrated with numerous Azure services, providing operational telemetry to analyze the cloud and on-premise services behaviour and performance, allowing to query and visualize the data and trigger alarms based on thresholds or patterns detected by~artificial intelligence to proactively notify about anomalies or issues
       \item Azure DevOps --- Cloud hosted service, providing a fully-fledged set of operational tools such as code repository and task management capabilities, enabling configuration of continuous integration and continuous delivery pipelines along with building artifacts and deploying software to multiple platform or on-premise services.
   \end{itemize}
\end{enumerate}

\subsection{Google Cloud Platform}

Google introduced its serverless products from their cloud offering in 2018 into general availability, after a long period in beta. It is noticeable that the Google Cloud Platform offering is not as rich and varied, and the services are not as mature and configurable, as~those offered in the AWS or Azure catalog.

The vendor is looking to cooperate closely with companies trying to scale quickly and startups, rather than large enterprises. Besides the serverless platform, the provider is~highly focused on containerization and microservice architecture, with the leading in~the Kubernetes services along with strong open-source commitments and DevOps-friendly approach. Google Cloud Platform is a leader in fields of artificial intelligence, machine learning and big data, offering numerous services and capabilities based on the open-source frameworks and libraries maintained by Google.

The provider gives a better impression to its customers in terms of the ease of setup and user-friendliness of the platform. The pricing model is aimed to be more customer friendly, offering exceptionally flexible contracts, appealing to customers interested in using the cloud.

Google Cloud Platform services, based on the available offer \cite{GCPServerlessOffering}, are presented below:

\begin{enumerate}
   \item Compute
   \begin{itemize}
       \item Cloud Function --- FaaS platform from Google, enabling to run the code without server management, scalable with the size of workload. Currently it supports Node.js, Python, Go, Java, .Net and Ruby runtimes. It is priced based on~number of invocation and execution duration with granularity to 100ms.
       \item Cloud Run --- Scalable and fully-managed container-based execution environment built on top of the Knative open-source project, triggered based on various platform events, automatically replicated across multiple regions and billed according to actual usage.
       \item App Engine --- Hosting platform for mostly web applications written in Node.js, Java, Ruby, C\#, Go, Python, or PHP, responsible for managing the infrastructure and scaling the solution
   \end{itemize}
   \item Data Store
   \begin{itemize}
       \item Cloud Storage --- Object storage ensuring security, durability, data access with low latency and geo-redundancy, enabling to store data across different storage classes characterised with different parameters and cost.
       \item Cloud SQL --- Managed and cloud-based relational database service for MySQL, PostgreSQL and SQL Server, ensuring reliability, automate database provisioning and storage management.
       \item Cloud Spanner --- Database with relational semantics and strong consistency with unlimited scaling, delivering high-performance transactions across regions, automatically handling scaling and sharding
       \item Firestore --- Serverless NoSQL document database, scaling with the demand with no maintenance overhead, with built-in live synchronization, ACID transactions and offline support. Designed to be used with mobile, web and IoT applications with direct connection to the clients, integrating with other Google Cloud Platform services.
       \item Cloud BigTable --- Fully-managed and scalable NoSQL database service, designed for machine learning and big data services, seamlessly scaling to~the~storage needs, capable of processing high-throughput data with low latency
       \item Memorystore --- Low latency, scalable and secure in-memory service, compatible with Redis and Memcached, enabling high-availability, automatic failover, patching and monitoring.
   \end{itemize}
   \item Network and Content Delivery
   \begin{itemize}
       \item Cloud Endpoints --- Development, deployment and management tool for APIs, providing logging, monitoring, access control and integrations with third party services as identity providers.
       \item Cloud CDN --- Globally distributed and reliable Content Delivery Network (CDN) for images, videos, webpages integrating with other services and supporting hybrid and multi-cloud architectures.
   \end{itemize}
   \item Application Integrations
   \begin{itemize}
       \item Cloud Pub/Sub --- Event-driven messaging system and analytics stream, auto-scalable, with no provisioning and cross-zone message replication, enabling in-order messaging with push and pull models
       \item Cloud Tasks --- Fully managed service that allows to handle and distribute vast number of distributed tasks asynchronously, building more decoupled applications in microservice architecture that can be scaled independently
       \item Cloud Scheduler --- Managed cron job service suitable for batch and big data jobs as well as cloud infrastructure operations, automating tasks management and handling retries in case of failures.
       \item Workflows --- Workflow orchestration service, integrated with multiple Google Cloud Platform components, focusing on modeling workflow logic, executing it~in~a~reliable way, passing the execution state between particular steps.
   \end{itemize}
   \item Analytics
   \begin{itemize}
       \item BigQuery --- Serverless data warehouse based on real-time data stream with autoscaling and managed infrastructure, enabling multi-cloud capabilities, integrated with many tools and services of Google Cloud Platform in the fields of machine learning, artificial and business intelligence.
   \end{itemize}
   \item Security and Identity
   \begin{itemize}
       \item Identity and Access Management (IAM) --- Service provides management capabilities for fine-grained access control for Google Cloud Platform resources along with monitoring and auditing them.
       \item Cloud Identity --- Service providing unified Identity and Access Management for~applications and endpoints, enforce strong security and access control, enabling access to thousands of applications via single sign-on
   \end{itemize}
   \item Development Tools
   \begin{itemize}
       \item Cloud Build --- Serves as a serverless service for building, testing and deploying artifacts and applications, utilising integration and continuous delivery pipelines
       \item Cloud Logging --- Real-time log management and analysis services, capable of~extracting data from logs and analyzing them in real-time.
       \item Cloud Monitoring --- Service for collecting metrics from various sources, visualising them. It monitors applications and services behaviour, and integrate with other third party solutions to provide better visibility and observability of~the~system.
       \item Cloud Trace, Cloud Debugger, Cloud Profiler --- Set of tools helping developers with tracing events in the distributed system and collecting numerous metrics, debugging the production application to get more insight into their behavior and profiling the application performance and resource utilisation.
   \end{itemize}
\end{enumerate}

In addition to the Google Cloud Platform services, Firebase \cite{Firebase} is another and~independent service, backed by Google and based on their cloud platform, providing BaaS components that can be directly integrated with web and mobile clients. All of the services are auto-scalable and with the infrastructure managed on the provider side. The~core~feature is a real-time document database utilising Firestore underneath, integrating with Cloud Functions, Cloud Storage and providing authentication capabilities. Moreover, the~offering includes other components that allow developers to monitor the performance and stability of applications as well as analyse the customers behaviour using A/B testing, boosting their engagement by in-app and cloud messaging.

\subsection{Other cloud providers and services}

\subsubsection{IBM}
IBM Cloud focuses on helping enterprises migrate to the cloud, extend their capabilities and transform their workloads to be more agile utilising cloud infrastructure. Over~the~years the company invested in industry-focused cloud services and hybrid cloud market, supporting diverse workloads including SAP, Oracle ERP and newer technologies including machine learning capabilities. Company promotes the open-source initiatives to~produce the~results, along with portable components that can be used among multiple cloud providers \cite{Gartner}.

In terms of serverless components, IBM Cloud Functions is based on open-sourced Apache OpenWhisk platform, which manages the infrastructure and scaling using Docker containers and can be deployed independently on top of popular container frameworks like Kubernetes, Mesos or OpenShift. The platform supports a programming model in which functions (called Actions) are dynamically provisioned in response to associated events (called Trigger) coming from numerous external sources or HTTP requests. Currently, OpenWhisk supports a large number of environments, such as Node.js, Go, Java, Scala, PHP, Python, Ruby, Swift or any executable running inside the Docker container \cite{ApacheOpenWhisk}.

\subsubsection{Alibaba Cloud}

Alibaba Cloud is a cloud provider that have a strong ties with Chinese public sector as~well as cooperates with numerous companies operating in the China and Southeast Asia region. The cloud vendor supports its clients with cloud migration and helps traditional enterprises to build their presence in the digital platforms. Most of its clients reported satisfaction with the platform solutions, but the limitations can be noticed in a modest international offerings compared to the services available in China region. Moreover, the~discrepancies in documentation and functionalities availability \cite{Gartner} occur.

The Function Compute is a serverless FaaS offering with a pay-as-you-go model, managed and scaled by~the cloud provider in response to events incoming from various data sources. It supports mainly Node.js, Python, Java, PHP, C\# and custom runtimes in~containers. The cloud platform provides two function instances --- the flexible functions, and~instances with the higher specifications for better performance. Additionally, vendor offers reserved instances that are always on, reducing the ''cold start'' \cite{AlibabaFunctionCompute}.

\subsubsection{Cloudflare}

Cloudflare is a company providing services in areas of web infrastructure and website security, such as Content Delivery Network, domain name servers and internet security services, serving as reverse proxy for websites. It also provides numerous analytics that gives insight into transfer speed, incoming traffic from unique users and their geographic location.

From serverless offerings, Cloudflare Workers are a FaaS platform based on the edge computing, providing high-performance. The solution is also managed, auto-scalable and~billed in a pay-per-use model, similar to other serverless offerings, but the difference is~in~the Cloudflare's edge network, that routes the request to the closest location where the function is executed, limiting the latency and providing high availability. Currently, the platform supports Node.js, Rust, C, and C++ as~an~execution runtimes \cite{CloudflareWorkers}.

\subsubsection{Oracle}

Oracle Cloud is expanding its worldwide presence and their cloud services into numerous regions, developing hyperscale cloud architectures that are competitive with other, more-established cloud providers. The vendor tends to cooperate more closely with enterprises, using its business applications and enable to incorporate and integrate them within the~cloud~platform. All of the cloud offerings are available in multiple regions with the same capabilities \cite{Gartner}.

Oracle Cloud Functions are offered in pay-as-you-go model, managed and scaled by~the provider and they are based on the open-source Fn Project and CloudEvents, which is~an~open-source specification for describing event data. It supports Go, Java, Node.js, Python, Ruby and C\# programming languages and custom runtimes using Docker to~execute the functions. The platform is vendor-agnostic and can be also executed in private and hybrid cloud \cite{FnProject}.

\subsubsection{Netlify}

Netlify is offering hosting and serverless backend services for static websites and web applications. The deployment process is easy and convenient for developers, which can connect Git repositories with the platform, enabling automatic continuous deployment triggered with every code change. Netlify extended its portfolio with other services such as serverless form submission, user identity management, analytics and also their own headless content management system, which can be utilised by dynamic web applications.

Currently, the offer also includes serverless functions powered by AWS Lambda, that can be automatically provisioned when the platform detects the configuration in the linked repository. The Netlify Functions can be triggered based on HTTP request to the defined API endpoint or form submission, as well as enabled to run asynchronous processing in~Background Functions with longer execution time. Altogether with the whole platform, it allows developers to quickly and easily setup the production environment for the web application or static website without any operational knowledge \cite{NetlifyFunction}.

\subsection{Open-source alternatives}

The benefits of serverless architecture, such as cost reduction and eliminating the need of~infrastructure management, became an appealing argument to use the technology. Nevertheless, some companies invested heavily in their hardware infrastructure, are afraid of~the~vendor lock-in or computation restriction of the public cloud platforms. Open-source frameworks are promising to overcome these limitations and manage the serverless components on self-hosted environment or hybrid clouds.

According to the aforementioned survey conducted by CNCF \cite{CNCFServerlessSurvey2020}, the most popular solution in the category of installable software for serverless function execution is~newly added Knative (claimed to be used by 27\% of respondents), while OpenFaaS maintains its~popularity (used by 10\% of interviewee) with Kubeless (mentioned by 5\% of~respondents).

All of the projects are based on the Kubernetes as a portable and extensible platform, enabling declarative configuration and management for containerized environments. Serverless frameworks rely on it to orchestrate and manage the serverless functions inside containers, schedule their executions, provide service discovery and replication. Each of~the open-sourced serverless frameworks approach the container orchestration is slightly different. For example, OpenFaas provides its own API Gateway, providing access to~the function, collecting metrics and scaling the solution, while others like Knative, utilise third party Ingress Controller for Kubernetes and manage the scaling by Queue-Proxy Container, passing the events to functions inside the pod. Several articles consider the~viability and quality of services for the open-source serverless platforms \cite{OpenSourceServelessPerformance}, considering also interesting possibilities of utilising serverless in edge computing \cite{OpenSourceServelessEdge}.

Nevertheless, utilising open-source platforms raises questions about maturity of these frameworks and introduces another set of challenges, which need to be researched and~addressed. Based on the previously mentioned papers some of the self-hosted serverless platforms show issues with scaling, lack of predictability and guaranteeing good quality of~service. Each of the frameworks provides default fault tolerance for container runtime, limited to retrying the execution which sometimes may be not suitable. All~of~the public cloud providers mendtioned above tend to supply various tools and services that support developers with log aggregation, monitoring, alerting and distributed tracing across the~serverless components, which requires manual integration in the open-source alternatives. Public cloud vendors offer not only the FaaS platforms, but also provide a~large variety of~BaaS components that can be integrated with serverless functions to build fully-fledged applications and services. This is in contrary to the open-sourced alternatives, which focus solely on the FaaS platforms. While the other components could be~also self-hosted, integration with them as well as scaling requires manual management on~the~customer side, increasing the amount of work that needs to be done to maintain the services quality and going against the idea of serverless.

\section{Example use cases} \label{chapter:serverless-example-use-cases}

\subsection{Application backend} \label{chapter:serverless-example-application-backend}

Serverless technologies are an appropriate solution for building scalable application backends for all kinds of web, mobile and desktop applications. They are favorable for this use-case, because the infrastructure management can be effectively automated, ensuring dynamic scaling to meet uneven demand, with proportional and predictable billing. Despite the fact that serverless technologies are a relatively new approach to building services, some of the companies have already used it to power large applications.

To build the application backend, serverless functions are used to transform the data representing the application logic, together with other third party services capable of persisting data or exposing some desired functionalities. The API Gateway provides uniform access to various serverless functions using REST API, preserving mapping between requests and respective serverless functions, enabling integrations with other services, for~example responsible for authentication and authorisation. Sending a request to the API can lead to execution of one or more serverless functions, containing custom business logic and~communicating respectively with other services. It is also possible that the frontend application can communicate directly with external components, bypassing the API Gateway. Nevertheless, it is essential to handle the communication in a secure manner using the~delegation tokens \cite{ServerlessArchitectureOnAWS}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{assets/02-serverless/CloudGuruArchitecture.png}
    \caption{CloudGuru platform architecture}
    \label{fig:cloudguru-architecture-diagram}
\end{figure}

CloudGuru, which is an online educational platform dedicated to people interested in~learning numerous cloud related topics, is a good example of such an use-case. Core~features of the platform include streaming large selection of video courses, interactive quizzes and practice exams, real-time discussion forum and integrations with third party services, enabling users to buy access to the courses.

The architecture of the e-learning platform utilises services of several cloud providers. Frontend of the web application built as a Single Page Application is hosted on Netlify, which acts as a Content Delivery Network (CDN) for the web client. Auth0 service is~responsible for authentication functionalities and provides delegation tokens for client application, communicating directly and securely with other services. Firebase is used as~a~primary database, which is capable of updating clients in real-time using WebSockets to push the data to the client applications. Questions and answers submitted by users to the forum are persisted in the Firebase, with the data being sent further to the AWS CloudSearch, which is indexing it for searching purpose and enabling users to later find information easier. Instructors can upload video directly to S3 bucket, that triggers the~video transcoding pipeline. Users can watch the videos served via CloudFront acting as~a~CDN, if they call the Lambda function beforehand, which gives them the permission to~access the video assets for a limited period of time.

\subsection{Event-driven data processing} \label{chapter:serverless-example-event-drive-processing}

Serverless has also found application in numerous media conversion and transcoding as~well as various data processing tasks. When the new file is inserted to the bucket responsible for data storage, it can trigger a serverless function passing the necessary data and file as~an~event to perform the processing. Such an event-driven approach is suitable for~building pipelines for data-processing tasks, billed only for the function execution time and other BaaS components usage to transfer, transform or extract some information \cite{ServerlessArchitectureOnAWS}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{assets/02-serverless/MindMupArchitecture.png}
    \caption{MindMup platform architecture for file export}
    \label{fig:mindmup-architecture-diagram}
\end{figure}

An example of such serverless utilisation is MindMup, which is a popular web application serving a role of a mind mapping tool, which was initially developed by just 2 developers. The event-driven data processing is utilised when a user wants to export prepared diagram to some read-only format such as PDF, Word document, presentation or text file. The web application works as interactive user interface. Upon user requests to export the~diagram, it calls the Lambda placed behind the API Gateway to generate the presigned URL, which can be used for a short period of time to insert the file directly from the client application to the S3 bucket. It sends an event to the Amazon Simple Notification Service (SNS) triggering the appropriate function responsible for export to~a~particular file format. Each of the exporters have different requirements, for~example CPU and memory usage for PDF exporter is much higher than for others, while Microsoft Office exporters require usage of libraries written in Java. Moreover, some of~the extensions such as Markdown are not as frequently selected by users. When the processing is~complete, the output of~the process is inserted to the S3 bucket, where the users can access it. Additionally, the event is sent to SNS which triggers other services such as DynamoDB, that are listening to that topic to save some information for analytics purpose.

The company admits that initially, the service responsible for exporting was running on the Heroku platform in the containerised environment, but after migration to the AWS Lambda, they have noticed significant cost reduction even with the growth of the platform usage by the clients \cite{ServerlessApplicationsWithNodejs}.

\subsection{Real-time stream processing}

Serverless architecture also found application in the data ingestion tasks from numerous data sources, such as logs, system events, transactions or social media feeds that need to~be~analyzed, aggregated and stored. Utilising BaaS components capable of event stream aggregation over time with the serverless function which can be configured to run when the specific number of records (forming a batch of records) is available. Such a messaging pattern is popular in distributed systems, where it allows to decouple the services and~provides reliability by storing the messages in the queue, when the consuming service cannot process more data at the moment, additionally providing retry mechanism in case of failures \cite{ServerlessArchitectureOnAWS}.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{assets/02-serverless/TemenosArchitecture.png}
    \caption{Temenos platform architecture}
    \label{fig:temenos-architecture-diagram}
\end{figure}

Temenos, as one of the largest banking software providers, is using such a pattern along with other serverless technologies in their T24 Transact banking system to achieve a highly elastic solution with low maintenance cost. It supports a large number of interactions and transactions between banking customers worldwide. Due to leveraging the platform and managed services, it reports that even the unpredictable workloads due to peaks in the market are handled efficiently. All the requests coming to the systems are getting through the AWS API Gateway. It passes them to the AWS Elastic Load Balancer (ELB), responsible for routing the requests to proper container instance running on AWS Fargate. The application running inside the container, performs the business actions based on the request and persists the result in Amazon Relational Database Service (Amazon RDS) that is an Online Transactional Processing Database (OLTP) designed to process the transactions effectively. Later, the stream of data and more complex business events is~pushed from Amazon RDS to Amazon Kinesis, which aggregates the data and triggers the AWS Lambda responsible for processing it, to build a query-optimized data model which is stored in DynamoDB. When the banking system users want to read the data, they perform a request that goes from API Gateway to AWS Lambda, that queries the~read-optimized data model from DynamoDB \cite{ThisIsMyAchitectureTemenos}.

\subsection{IoT applications}

With the growth of smart homes popularity, IoT devices along with other machines that are meant to help people, started incorporating more sophisticated technologies to support people on a daily basis. iRobot is a leading company in terms of designing and building smart robots, helping people around their household, with the Roomba robotic vacuums as their most popular product. Besides robotics, the company provides iRobot HOME application which enables customers to interact with their smart home devices.

\begin{figure}[h]
    \centering
    \includegraphics[width=0.7\textwidth]{assets/02-serverless/iRobotArchitecture.png}
    \caption{iRobot solution architecture for smart robots}
    \label{fig:irobot-architecture-diagram}
\end{figure}

AWS IoT is an entry point for the Roomba vacuums to connect them with the cloud. For the communication purposes MQTT is used, which is a lightweight publish-subscribe protocol for IoT devices. The AWS IoT Shadow Device provides asynchronous communication mechanism, enabling the robot to work properly without the constant communications with the cloud. When the smart vacuum finishes cleaning job, its data is synchronized with the cloud, which allows users to update the cleaning schedule, accordingly to changes made in the iRobot HOME application. Along with the AWS IoT, developers can define additional IoT Rules that configure the device to connect with other services in the cloud, for example to update the device status along with its parameters or informing users that the vacuum tank is full. Moreover, it gathers additional information about usage and~home~mapping to better plan device's tasks and manage the battery power \cite{ServerlessIoTatiRobot}.

Developers and designers of the robotics solutions observed many benefits related to the utilisation of cloud vendor services and the serverless paradigm, mentioning the scalability of the solution without the need to manage infrastructure and significant cost reduction, while preserving the proper level of security and data privacy \cite{AWSIRobotIoT}.